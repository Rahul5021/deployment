{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/air_quality_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "      <th>Air Quality</th>\n",
       "      <th>weighted_pollution</th>\n",
       "      <th>pm_fine_ratio</th>\n",
       "      <th>population_exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>49.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>26.6</td>\n",
       "      <td>42.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>748</td>\n",
       "      <td>Hazardous</td>\n",
       "      <td>20.05</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>63146.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>35.7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>52.7</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.51</td>\n",
       "      <td>6.9</td>\n",
       "      <td>659</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>39.06</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>85742.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>39.9</td>\n",
       "      <td>78.7</td>\n",
       "      <td>71.9</td>\n",
       "      <td>85.2</td>\n",
       "      <td>39.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3.3</td>\n",
       "      <td>957</td>\n",
       "      <td>Hazardous</td>\n",
       "      <td>63.89</td>\n",
       "      <td>0.843897</td>\n",
       "      <td>206367.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>31.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.0</td>\n",
       "      <td>643</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>51369.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>38.2</td>\n",
       "      <td>82.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.60</td>\n",
       "      <td>5.2</td>\n",
       "      <td>696</td>\n",
       "      <td>Poor</td>\n",
       "      <td>16.97</td>\n",
       "      <td>0.316981</td>\n",
       "      <td>48372.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature  Humidity  ...  pm_fine_ratio  population_exposure\n",
       "4055         49.6      91.0  ...       0.285714             63146.16\n",
       "4350         35.7      53.1  ...       0.823529             85742.49\n",
       "3066         39.9      78.7  ...       0.843897            206367.48\n",
       "2581         31.4      69.8  ...       0.637500             51369.27\n",
       "2929         38.2      82.1  ...       0.316981             48372.00\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Air Quality'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "      <th>weighted_pollution</th>\n",
       "      <th>pm_fine_ratio</th>\n",
       "      <th>population_exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>319</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>16881.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3</td>\n",
       "      <td>75.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>611</td>\n",
       "      <td>11.71</td>\n",
       "      <td>0.188525</td>\n",
       "      <td>34607.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.2</td>\n",
       "      <td>619</td>\n",
       "      <td>26.96</td>\n",
       "      <td>0.789941</td>\n",
       "      <td>61361.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.1</td>\n",
       "      <td>551</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>17824.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12.7</td>\n",
       "      <td>303</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.431250</td>\n",
       "      <td>15577.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  ...  pm_fine_ratio  population_exposure\n",
       "0         29.8      59.1  ...       0.290503             16881.48\n",
       "1         28.3      75.6  ...       0.188525             34607.04\n",
       "2         23.1      74.7  ...       0.789941             61361.47\n",
       "3         27.1      39.1  ...       0.968254             17824.85\n",
       "4         26.5      70.7  ...       0.431250             15577.23\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Air Quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Moderate\n",
       "1    Moderate\n",
       "2    Moderate\n",
       "3        Good\n",
       "4        Good\n",
       "Name: Air Quality, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Separate features by type\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# Create transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "cat_transformer = LabelEncoder()\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),  # Apply StandardScaler to numeric features\n",
    "        (\"cat\", cat_transformer, cat_features)       # Apply custom LabelEncoder to categorical features\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are infinite values in the numeric columns.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "if X.isnull().values.any():\n",
    "    print(\"There are NaN values in the feature dataset.\")\n",
    "    X = X.fillna(X.mean())  # Fill NaN values with the mean of each column\n",
    "\n",
    "# Check for infinite values in numeric columns of X\n",
    "numeric_columns = X.select_dtypes(include=np.number).columns\n",
    "if np.isinf(X[numeric_columns].values).any():\n",
    "    print(\"There are infinite values in the numeric columns.\")\n",
    "    X[numeric_columns] = X[numeric_columns].replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "\n",
    "# Fill NaN values in numeric columns (after replacing infinities) with the mean\n",
    "X[numeric_columns] = X[numeric_columns].fillna(X[numeric_columns].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 0, 2], shape=(5000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    report = classification_report(true, predicted)\n",
    "    matrix = confusion_matrix(true, predicted)\n",
    "    return accuracy, report, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for training set: \n",
      "- Accuracy: 0.9445\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1591\n",
      "           1       0.89      0.84      0.86       389\n",
      "           2       0.95      0.96      0.95      1206\n",
      "           3       0.87      0.87      0.87       814\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n",
      "- Confusion Matrix:  [[1588    0    3    0]\n",
      " [   0  326    0   63]\n",
      " [  11    0 1155   40]\n",
      " [   0   41   64  709]]\n",
      "---------------------------------------------------------\n",
      "Model performance for test set:\n",
      "- Accuracy: 0.945\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       409\n",
      "           1       0.92      0.81      0.86       111\n",
      "           2       0.96      0.95      0.96       294\n",
      "           3       0.83      0.89      0.86       186\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.93      0.91      0.92      1000\n",
      "weighted avg       0.95      0.94      0.95      1000\n",
      "\n",
      "- Confusion Matrix:  [[409   0   0   0]\n",
      " [  0  90   0  21]\n",
      " [  0   0 280  14]\n",
      " [  0   8  12 166]]\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for training set: \n",
      "- Accuracy: 1.0\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1591\n",
      "           1       1.00      1.00      1.00       389\n",
      "           2       1.00      1.00      1.00      1206\n",
      "           3       1.00      1.00      1.00       814\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "- Confusion Matrix:  [[1591    0    0    0]\n",
      " [   0  389    0    0]\n",
      " [   0    0 1206    0]\n",
      " [   0    0    0  814]]\n",
      "---------------------------------------------------------\n",
      "Model performance for test set:\n",
      "- Accuracy: 0.908\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       409\n",
      "           1       0.81      0.82      0.81       111\n",
      "           2       0.93      0.89      0.91       294\n",
      "           3       0.75      0.78      0.77       186\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "- Confusion Matrix:  [[409   0   0   0]\n",
      " [  0  91   0  20]\n",
      " [  3   0 263  28]\n",
      " [  0  22  19 145]]\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for training set: \n",
      "- Accuracy: 1.0\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1591\n",
      "           1       1.00      1.00      1.00       389\n",
      "           2       1.00      1.00      1.00      1206\n",
      "           3       1.00      1.00      1.00       814\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "- Confusion Matrix:  [[1591    0    0    0]\n",
      " [   0  389    0    0]\n",
      " [   0    0 1206    0]\n",
      " [   0    0    0  814]]\n",
      "---------------------------------------------------------\n",
      "Model performance for test set:\n",
      "- Accuracy: 0.962\n",
      "- Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       409\n",
      "           1       0.93      0.89      0.91       111\n",
      "           2       0.97      0.97      0.97       294\n",
      "           3       0.89      0.91      0.90       186\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.95      0.94      0.94      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "- Confusion Matrix:  [[409   0   0   0]\n",
      " [  0  99   0  12]\n",
      " [  0   0 284  10]\n",
      " [  0   7   9 170]]\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "model_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_accuracy, model_train_report, model_train_matrix = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_accuracy, model_test_report, model_test_matrix = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model performance for training set: \")\n",
    "    print(\"- Accuracy: {:.4}\".format(model_train_accuracy))\n",
    "    print(\"- Report: \", model_train_report)\n",
    "    print(\"- Confusion Matrix: \", model_train_matrix)\n",
    "\n",
    "    print(\"---------------------------------------------------------\")\n",
    "\n",
    "    print(\"Model performance for test set:\")\n",
    "    print(\"- Accuracy: {:.4}\".format(model_test_accuracy))\n",
    "    print(\"- Report: \", model_test_report)\n",
    "    print(\"- Confusion Matrix: \", model_test_matrix)\n",
    "\n",
    "    accuracy_list.append(model_test_accuracy)\n",
    "\n",
    "    print(\"=\"*35)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Accuracy Score\n",
       "2        Random Forest           0.962\n",
       "0  Logistic Regression           0.945\n",
       "1        Decision Tree           0.908"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, accuracy_list)), columns=['Model Name', 'Accuracy Score']).sort_values(by=[\"Accuracy Score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 95.70\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Accuracy of the model is: %.2f\"%accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Value  Predicted Value  Difference\n",
       "0               1                1           0\n",
       "1               0                0           0\n",
       "2               2                2           0\n",
       "3               1                1           0\n",
       "4               0                0           0\n",
       "..            ...              ...         ...\n",
       "995             2                2           0\n",
       "996             0                0           0\n",
       "997             3                3           0\n",
       "998             2                2           0\n",
       "999             3                3           0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
